{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "data_dir = \"D:/MLiP/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_one_hot(labels):\n",
    "    \n",
    "    onehot_label = [0.] * 228\n",
    "    for label in labels:\n",
    "        onehot_label[int(label) - 1] = 1.\n",
    "    \n",
    "    return onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9897, 228)\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame.from_csv('validation_prediction.csv')\n",
    "predictions = predictions_df.values\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9897, 228)\n"
     ]
    }
   ],
   "source": [
    "ground_truth = pd.DataFrame.from_csv(join(data_dir, \"csv/valid_labels.csv\"))\n",
    "labels_gt = []\n",
    "for i in range(9897):\n",
    "    row = ground_truth.iloc[i, :]\n",
    "    label = labels_one_hot(ast.literal_eval(row['labelId']))\n",
    "    labels_gt.append(label)\n",
    "labels_gt = np.array(labels_gt)\n",
    "print(labels_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_thresholds(true, pred, epochs=10):\n",
    "    \n",
    "    # Assert true and pred have same shape\n",
    "    dims = true.shape\n",
    "    assert(dims == pred.shape)\n",
    "\n",
    "    # Initialize values to be filled in, thresholds start at 0.1\n",
    "    best_f1 = 0.\n",
    "    best_threshold = np.array([0.5] * 228)\n",
    "    \n",
    "    # Loop through epochs\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # Loop through labels\n",
    "        for j in range(dims[1]):\n",
    "            \n",
    "            print('Fine-tuning label:', j+1)\n",
    "            \n",
    "            # Variable to determine when to move on to next label\n",
    "            improved = 2\n",
    "            \n",
    "            # Loop to find optimal threshold for label j\n",
    "            for k in np.linspace(0.1, 1, 10):\n",
    "                \n",
    "                if improved == 0:\n",
    "                    print('Stopped fine-tuning label ' + str(j+1) + ' after ' + str(int(k * 10 - 1)) + ' tries.\\n')\n",
    "                    break\n",
    "                \n",
    "                # Create copy of thresholds to mute in the loop\n",
    "                thresholds = copy.copy(best_threshold)\n",
    "                \n",
    "                # Set new threshold\n",
    "                thresholds[j] = k\n",
    "                \n",
    "                # Threshold predictions\n",
    "                thresholded_pred = np.zeros(dims)\n",
    "                for l in range(dims[0]):\n",
    "                    thresholded_pred[l] += pred[l] > thresholds\n",
    "\n",
    "                # Calculate \n",
    "                f1 = np.mean(np.array([fbeta_score(true[x], thresholded_pred[x], beta=1) for x in range(dims[0])]))\n",
    "\n",
    "                # Update score if necessary\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_threshold = copy.copy(thresholds)\n",
    "                    print('F1-score improved to:', best_f1)\n",
    "                else:\n",
    "                    improved -= 1\n",
    "        \n",
    "    return best_f1, best_theshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score improved to: 0.4635488255016373\n",
      "Stopped fine-tuning label 1 after 3 tries.\n",
      "Fine-tuning label: 2\n",
      "Stopped fine-tuning label 2 after 2 tries.\n",
      "Fine-tuning label: 3\n",
      "F1-score improved to: 0.46361162182087495\n",
      "Stopped fine-tuning label 3 after 3 tries.\n",
      "Fine-tuning label: 4\n",
      "F1-score improved to: 0.4638202611282842\n",
      "Stopped fine-tuning label 4 after 3 tries.\n",
      "Fine-tuning label: 5\n",
      "F1-score improved to: 0.46382567724018536\n",
      "F1-score improved to: 0.46383244680279184\n",
      "F1-score improved to: 0.4638690228927173\n",
      "Stopped fine-tuning label 5 after 5 tries.\n",
      "Fine-tuning label: 6\n",
      "F1-score improved to: 0.46394960760500864\n",
      "Stopped fine-tuning label 6 after 3 tries.\n",
      "Fine-tuning label: 7\n",
      "Stopped fine-tuning label 7 after 2 tries.\n",
      "Fine-tuning label: 8\n",
      "Stopped fine-tuning label 8 after 2 tries.\n",
      "Fine-tuning label: 9\n",
      "Stopped fine-tuning label 9 after 2 tries.\n",
      "Fine-tuning label: 10\n",
      "F1-score improved to: 0.46409513080297204\n",
      "Stopped fine-tuning label 10 after 3 tries.\n",
      "Fine-tuning label: 11\n",
      "Stopped fine-tuning label 11 after 2 tries.\n",
      "Fine-tuning label: 12\n",
      "F1-score improved to: 0.46410031237832633\n",
      "Stopped fine-tuning label 12 after 3 tries.\n",
      "Fine-tuning label: 13\n",
      "Stopped fine-tuning label 13 after 2 tries.\n",
      "Fine-tuning label: 14\n",
      "F1-score improved to: 0.46417734737503397\n",
      "Stopped fine-tuning label 14 after 3 tries.\n",
      "Fine-tuning label: 15\n",
      "F1-score improved to: 0.4649043286317658\n",
      "Stopped fine-tuning label 15 after 3 tries.\n",
      "Fine-tuning label: 16\n",
      "Stopped fine-tuning label 16 after 2 tries.\n",
      "Fine-tuning label: 17\n",
      "F1-score improved to: 0.4876756712179799\n",
      "F1-score improved to: 0.4879711059569368\n",
      "Stopped fine-tuning label 17 after 4 tries.\n",
      "Fine-tuning label: 18\n",
      "F1-score improved to: 0.4890734435165993\n",
      "F1-score improved to: 0.48942275902414645\n",
      "Stopped fine-tuning label 18 after 4 tries.\n",
      "Fine-tuning label: 19\n",
      "F1-score improved to: 0.4930467957422908\n",
      "F1-score improved to: 0.49327376023850444\n",
      "Stopped fine-tuning label 19 after 4 tries.\n",
      "Fine-tuning label: 20\n",
      "F1-score improved to: 0.49335082412214915\n",
      "F1-score improved to: 0.49502019591101964\n",
      "F1-score improved to: 0.4951667380339042\n",
      "Stopped fine-tuning label 20 after 5 tries.\n",
      "Fine-tuning label: 21\n",
      "F1-score improved to: 0.49539222574178404\n",
      "Stopped fine-tuning label 21 after 3 tries.\n",
      "Fine-tuning label: 22\n",
      "F1-score improved to: 0.4954947099000427\n"
     ]
    }
   ],
   "source": [
    "score, thresh = get_optimal_thresholds(labels_gt, predictions, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True False]\n",
      "[0. 0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros(5)\n",
    "a = np.array([0.3, 0.5, 0.7, 0.9, 0.6])\n",
    "b = np.array([0.5, 0.5, 0.5, 0.5, 0.7])\n",
    "\n",
    "x += (a > b)\n",
    "print(a > b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes from ground truth and predictions\n",
    "#df_true = pd.DataFrame(true)\n",
    "#df_pred = pd.DataFrame(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "print(np.linspace(0.1, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
