{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# System\n",
    "import os\n",
    "from os.path import join, basename, dirname, exists\n",
    "\n",
    "# For submission\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "# Computational\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "\n",
    "# Images and augmentation\n",
    "from scipy.ndimage import imread\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# Analysis and plots\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "\n",
    "# Deep learning\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# Pre-trained models imports\n",
    "from keras.applications import vgg16, xception\n",
    "\n",
    "# Preprocessing imports\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Layer imports\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras import Model\n",
    "\n",
    "# Probably not needed anymore?\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "data_dir = \"D:/MLiP/data/\"\n",
    "#data_dir = \"F:/MLiP/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed for (testing) the batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(input_path, range_min=0, range_max=1):\n",
    "    \n",
    "    # Read image data (x, y, c) [0, 255]\n",
    "    image = imread(input_path)\n",
    "    \n",
    "    # Convert image to the correct range\n",
    "    # image = np.interp(image, [np.min(image), np.max(image)], [range_min, range_max])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_one_hot(labels):\n",
    "    \n",
    "    onehot_label = [0.] * 228\n",
    "    for label in labels:\n",
    "        onehot_label[int(label) - 1] = 1.\n",
    "    \n",
    "    return onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_augmentation(image): # Used for the BatchGenerator\n",
    "    \n",
    "    aug = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Scale({\"height\": 299, \"width\": 299})\n",
    "    ])\n",
    "    \n",
    "    image = aug.augment_images([image])[0] / 255\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(images, images_per_row=8):\n",
    "    \n",
    "    fig, axs = plt.subplots(int(np.ceil(len(images)/images_per_row)), images_per_row)\n",
    "    \n",
    "    c = 0\n",
    "    for ax_row in axs:\n",
    "        for ax in ax_row:\n",
    "            if c < len(images):\n",
    "                ax.imshow(images[c])\n",
    "            ax.axis('off')            \n",
    "            c += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-reating the image index per label dataframe\n",
    "I had some troubles parsing the .csv that Alex made, so I re-made it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning:\n",
      "\n",
      "from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "\n",
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning:\n",
      "\n",
      "from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the right csv\n",
    "basic_df = pd.DataFrame.from_csv(join(data_dir, \"csv/train_labels.csv\"))\n",
    "evaluated = basic_df['labelId'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Following code was use to re-create the .csv\n",
    "# label_images = [[] for _ in range(228)]\n",
    "# for i, row in enumerate(evaluated):\n",
    "#     for label in row:\n",
    "#         label_images[int(label)-1].append(i)\n",
    "\n",
    "# proper_df = pd.DataFrame(\n",
    "#     {'imageIdx': label_images,\n",
    "#      'labelId': list(range(1,229))     \n",
    "#     })\n",
    "# proper_df.head()\n",
    "# proper_df.to_csv('idx_per_label.csv')\n",
    "\n",
    "idx_csv_df = pd.DataFrame.from_csv(join(data_dir, 'csv/idx_per_label.csv'))\n",
    "idx_label_df = idx_csv_df['imageIdx'].apply(lambda x: ast.literal_eval(x)) # labels to int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how the label sampling works (code copied to generator)\n",
    "Plot shows that each label is selected at least once per macrobatch_size images. Original distribution is still very much the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "macrobatch_size = 1024\n",
    "\n",
    "image_ids = set([])\n",
    "labels = set([])\n",
    "all_labels = []\n",
    "\n",
    "label_range = list(range(1,229))\n",
    "random.shuffle(label_range)\n",
    "for label in [str(i) for i in label_range]:\n",
    "    if label not in labels:\n",
    "        # Add image with label to img_idx\n",
    "        img_id = random.choice(idx_label_df.iloc[int(label)-1]) + 1\n",
    "        image_ids = image_ids | set([img_id]) # add id\n",
    "\n",
    "        # Add labels from taken image to labels\n",
    "        new_labels = evaluated.iloc[img_id - 1]\n",
    "        labels = labels | set(new_labels)\n",
    "        all_labels.append(new_labels)\n",
    "\n",
    "while len(image_ids) < macrobatch_size:\n",
    "    image_ids = image_ids | set([random.randint(1, len(basic_df))])\n",
    "\n",
    "all_labels = [x for sublist in all_labels for x in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following plot with different macrobatch_size values to see how the distribution looks. Each label should have at least one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgba(20, 20, 20, 1)"
         },
         "name": "year count",
         "opacity": 0.8,
         "type": "bar",
         "x": [
          "217",
          "73",
          "15",
          "206",
          "53",
          "146",
          "150",
          "167",
          "181",
          "42",
          "140",
          "7",
          "81",
          "111",
          "219",
          "41",
          "24",
          "48",
          "14",
          "72",
          "44",
          "189",
          "149",
          "85",
          "109",
          "103",
          "119",
          "5",
          "114",
          "221",
          "84",
          "128",
          "205",
          "19",
          "60",
          "123",
          "210",
          "10",
          "121",
          "13",
          "83",
          "211",
          "100",
          "139",
          "182",
          "193",
          "135",
          "18",
          "125",
          "87",
          "4",
          "157",
          "23",
          "162",
          "16",
          "178",
          "166",
          "214",
          "20",
          "117",
          "47",
          "168",
          "104",
          "94",
          "208",
          "201",
          "134",
          "64",
          "68",
          "177",
          "225",
          "76",
          "56",
          "92",
          "9",
          "80",
          "8",
          "122",
          "151",
          "215",
          "32",
          "82",
          "102",
          "124",
          "31",
          "184",
          "200",
          "194",
          "107",
          "28",
          "138",
          "54",
          "131",
          "62",
          "172",
          "154",
          "89",
          "113",
          "191",
          "96",
          "66",
          "12",
          "116",
          "35",
          "227",
          "67",
          "11",
          "195",
          "202",
          "218",
          "105",
          "192",
          "99",
          "132",
          "38",
          "52",
          "61",
          "29",
          "143",
          "49",
          "91",
          "160",
          "71",
          "129",
          "142",
          "50",
          "34",
          "174",
          "185",
          "137",
          "165",
          "70",
          "69",
          "86",
          "65",
          "101",
          "216",
          "175",
          "187",
          "130",
          "30",
          "21",
          "196",
          "17",
          "148",
          "115",
          "78",
          "58",
          "22",
          "25",
          "75",
          "155",
          "226",
          "97",
          "6",
          "1",
          "152",
          "55",
          "77",
          "2",
          "220",
          "133",
          "170",
          "199",
          "153",
          "136",
          "228",
          "88",
          "159",
          "179",
          "224",
          "93",
          "3",
          "40",
          "147",
          "186",
          "27",
          "141",
          "173",
          "57",
          "188",
          "169",
          "180",
          "183",
          "26",
          "33",
          "120",
          "204",
          "158",
          "63",
          "36",
          "39",
          "176",
          "156",
          "209",
          "145",
          "223",
          "222",
          "98",
          "106",
          "212",
          "45",
          "59",
          "112",
          "207",
          "118",
          "95",
          "51",
          "163",
          "144",
          "197",
          "37",
          "126",
          "46",
          "108",
          "110",
          "79",
          "90",
          "213",
          "127",
          "74",
          "190",
          "161",
          "198",
          "43",
          "171",
          "164",
          "203"
         ],
         "y": [
          1,
          7,
          2,
          1,
          12,
          2,
          2,
          6,
          3,
          1,
          2,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          2,
          2,
          8,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          4,
          18,
          1,
          1,
          1,
          1,
          1,
          4,
          1,
          1,
          2,
          3,
          2,
          3,
          1,
          3,
          1,
          4,
          1,
          1,
          1,
          1,
          1,
          2,
          3,
          13,
          8,
          2,
          2,
          3,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          5,
          1,
          2,
          2,
          2,
          1,
          1,
          7,
          1,
          1,
          1,
          4,
          12,
          1,
          9,
          7,
          1,
          1,
          1,
          20,
          1,
          1,
          97,
          1,
          3,
          1,
          2,
          1,
          1,
          1,
          1,
          5,
          32,
          1,
          4,
          3,
          1,
          1,
          3,
          3,
          2,
          8,
          2,
          1,
          1,
          1,
          6,
          1,
          1,
          1,
          1,
          10,
          1,
          7,
          4,
          1,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          1,
          2,
          25,
          15,
          4,
          8,
          1,
          1,
          1,
          2,
          2,
          5,
          4,
          1,
          1,
          1,
          3,
          2,
          1,
          1,
          4,
          1,
          1,
          26,
          2,
          1,
          1,
          1,
          1,
          3,
          2,
          1,
          1,
          1,
          8,
          1,
          1,
          1,
          1,
          1,
          1,
          6,
          2,
          1,
          2,
          1,
          4,
          2,
          6,
          6,
          2,
          17,
          1,
          2,
          1,
          1,
          24,
          5,
          26,
          1,
          3,
          6,
          1,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          4,
          8,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          22,
          12,
          3
         ]
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h"
        },
        "title": "Distribution of different labels in the batch",
        "width": 800
       }
      },
      "text/html": [
       "<div id=\"b8666cab-2d29-4194-982d-005ec78feaf0\" style=\"height: 525px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b8666cab-2d29-4194-982d-005ec78feaf0\", [{\"y\": [1, 7, 2, 1, 12, 2, 2, 6, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 18, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 3, 1, 3, 1, 4, 1, 1, 1, 1, 1, 2, 3, 13, 8, 2, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 5, 1, 2, 2, 2, 1, 1, 7, 1, 1, 1, 4, 12, 1, 9, 7, 1, 1, 1, 20, 1, 1, 97, 1, 3, 1, 2, 1, 1, 1, 1, 5, 32, 1, 4, 3, 1, 1, 3, 3, 2, 8, 2, 1, 1, 1, 6, 1, 1, 1, 1, 10, 1, 7, 4, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 25, 15, 4, 8, 1, 1, 1, 2, 2, 5, 4, 1, 1, 1, 3, 2, 1, 1, 4, 1, 1, 26, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 6, 2, 1, 2, 1, 4, 2, 6, 6, 2, 17, 1, 2, 1, 1, 24, 5, 26, 1, 3, 6, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 4, 8, 1, 1, 1, 1, 2, 1, 1, 1, 22, 12, 3], \"name\": \"year count\", \"marker\": {\"color\": \"rgba(20, 20, 20, 1)\"}, \"opacity\": 0.8, \"type\": \"bar\", \"x\": [\"217\", \"73\", \"15\", \"206\", \"53\", \"146\", \"150\", \"167\", \"181\", \"42\", \"140\", \"7\", \"81\", \"111\", \"219\", \"41\", \"24\", \"48\", \"14\", \"72\", \"44\", \"189\", \"149\", \"85\", \"109\", \"103\", \"119\", \"5\", \"114\", \"221\", \"84\", \"128\", \"205\", \"19\", \"60\", \"123\", \"210\", \"10\", \"121\", \"13\", \"83\", \"211\", \"100\", \"139\", \"182\", \"193\", \"135\", \"18\", \"125\", \"87\", \"4\", \"157\", \"23\", \"162\", \"16\", \"178\", \"166\", \"214\", \"20\", \"117\", \"47\", \"168\", \"104\", \"94\", \"208\", \"201\", \"134\", \"64\", \"68\", \"177\", \"225\", \"76\", \"56\", \"92\", \"9\", \"80\", \"8\", \"122\", \"151\", \"215\", \"32\", \"82\", \"102\", \"124\", \"31\", \"184\", \"200\", \"194\", \"107\", \"28\", \"138\", \"54\", \"131\", \"62\", \"172\", \"154\", \"89\", \"113\", \"191\", \"96\", \"66\", \"12\", \"116\", \"35\", \"227\", \"67\", \"11\", \"195\", \"202\", \"218\", \"105\", \"192\", \"99\", \"132\", \"38\", \"52\", \"61\", \"29\", \"143\", \"49\", \"91\", \"160\", \"71\", \"129\", \"142\", \"50\", \"34\", \"174\", \"185\", \"137\", \"165\", \"70\", \"69\", \"86\", \"65\", \"101\", \"216\", \"175\", \"187\", \"130\", \"30\", \"21\", \"196\", \"17\", \"148\", \"115\", \"78\", \"58\", \"22\", \"25\", \"75\", \"155\", \"226\", \"97\", \"6\", \"1\", \"152\", \"55\", \"77\", \"2\", \"220\", \"133\", \"170\", \"199\", \"153\", \"136\", \"228\", \"88\", \"159\", \"179\", \"224\", \"93\", \"3\", \"40\", \"147\", \"186\", \"27\", \"141\", \"173\", \"57\", \"188\", \"169\", \"180\", \"183\", \"26\", \"33\", \"120\", \"204\", \"158\", \"63\", \"36\", \"39\", \"176\", \"156\", \"209\", \"145\", \"223\", \"222\", \"98\", \"106\", \"212\", \"45\", \"59\", \"112\", \"207\", \"118\", \"95\", \"51\", \"163\", \"144\", \"197\", \"37\", \"126\", \"46\", \"108\", \"110\", \"79\", \"90\", \"213\", \"127\", \"74\", \"190\", \"161\", \"198\", \"43\", \"171\", \"164\", \"203\"]}], {\"legend\": {\"orientation\": \"h\"}, \"title\": \"Distribution of different labels in the batch\", \"width\": 800}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"b8666cab-2d29-4194-982d-005ec78feaf0\" style=\"height: 525px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b8666cab-2d29-4194-982d-005ec78feaf0\", [{\"y\": [1, 7, 2, 1, 12, 2, 2, 6, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 18, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 3, 1, 3, 1, 4, 1, 1, 1, 1, 1, 2, 3, 13, 8, 2, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 5, 1, 2, 2, 2, 1, 1, 7, 1, 1, 1, 4, 12, 1, 9, 7, 1, 1, 1, 20, 1, 1, 97, 1, 3, 1, 2, 1, 1, 1, 1, 5, 32, 1, 4, 3, 1, 1, 3, 3, 2, 8, 2, 1, 1, 1, 6, 1, 1, 1, 1, 10, 1, 7, 4, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 25, 15, 4, 8, 1, 1, 1, 2, 2, 5, 4, 1, 1, 1, 3, 2, 1, 1, 4, 1, 1, 26, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 6, 2, 1, 2, 1, 4, 2, 6, 6, 2, 17, 1, 2, 1, 1, 24, 5, 26, 1, 3, 6, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 4, 8, 1, 1, 1, 1, 2, 1, 1, 1, 22, 12, 3], \"name\": \"year count\", \"marker\": {\"color\": \"rgba(20, 20, 20, 1)\"}, \"opacity\": 0.8, \"type\": \"bar\", \"x\": [\"217\", \"73\", \"15\", \"206\", \"53\", \"146\", \"150\", \"167\", \"181\", \"42\", \"140\", \"7\", \"81\", \"111\", \"219\", \"41\", \"24\", \"48\", \"14\", \"72\", \"44\", \"189\", \"149\", \"85\", \"109\", \"103\", \"119\", \"5\", \"114\", \"221\", \"84\", \"128\", \"205\", \"19\", \"60\", \"123\", \"210\", \"10\", \"121\", \"13\", \"83\", \"211\", \"100\", \"139\", \"182\", \"193\", \"135\", \"18\", \"125\", \"87\", \"4\", \"157\", \"23\", \"162\", \"16\", \"178\", \"166\", \"214\", \"20\", \"117\", \"47\", \"168\", \"104\", \"94\", \"208\", \"201\", \"134\", \"64\", \"68\", \"177\", \"225\", \"76\", \"56\", \"92\", \"9\", \"80\", \"8\", \"122\", \"151\", \"215\", \"32\", \"82\", \"102\", \"124\", \"31\", \"184\", \"200\", \"194\", \"107\", \"28\", \"138\", \"54\", \"131\", \"62\", \"172\", \"154\", \"89\", \"113\", \"191\", \"96\", \"66\", \"12\", \"116\", \"35\", \"227\", \"67\", \"11\", \"195\", \"202\", \"218\", \"105\", \"192\", \"99\", \"132\", \"38\", \"52\", \"61\", \"29\", \"143\", \"49\", \"91\", \"160\", \"71\", \"129\", \"142\", \"50\", \"34\", \"174\", \"185\", \"137\", \"165\", \"70\", \"69\", \"86\", \"65\", \"101\", \"216\", \"175\", \"187\", \"130\", \"30\", \"21\", \"196\", \"17\", \"148\", \"115\", \"78\", \"58\", \"22\", \"25\", \"75\", \"155\", \"226\", \"97\", \"6\", \"1\", \"152\", \"55\", \"77\", \"2\", \"220\", \"133\", \"170\", \"199\", \"153\", \"136\", \"228\", \"88\", \"159\", \"179\", \"224\", \"93\", \"3\", \"40\", \"147\", \"186\", \"27\", \"141\", \"173\", \"57\", \"188\", \"169\", \"180\", \"183\", \"26\", \"33\", \"120\", \"204\", \"158\", \"63\", \"36\", \"39\", \"176\", \"156\", \"209\", \"145\", \"223\", \"222\", \"98\", \"106\", \"212\", \"45\", \"59\", \"112\", \"207\", \"118\", \"95\", \"51\", \"163\", \"144\", \"197\", \"37\", \"126\", \"46\", \"108\", \"110\", \"79\", \"90\", \"213\", \"127\", \"74\", \"190\", \"161\", \"198\", \"43\", \"171\", \"164\", \"203\"]}], {\"legend\": {\"orientation\": \"h\"}, \"title\": \"Distribution of different labels in the batch\", \"width\": 800}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels = Counter(all_labels)\n",
    "\n",
    "xvalues = list(train_labels.keys())\n",
    "yvalues = list(train_labels.values())\n",
    "\n",
    "trace1 = go.Bar(x=xvalues, y=yvalues, opacity=0.8, name=\"year count\", marker=dict(color='rgba(20, 20, 20, 1)'))\n",
    "layout = dict(width=800, title='Distribution of different labels in the batch', legend=dict(orientation=\"h\"));\n",
    "\n",
    "fig = go.Figure(data=[trace1], layout=layout);\n",
    "iplot(fig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The generator\n",
    "Takes a while to initialize but should be pretty fast at creating batches after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, input_dir, csv_path, mini_batch_size=32, macro_batch_size=512, augmentation_fn=basic_augmentation):\n",
    "\n",
    "        # Params\n",
    "        self.input_dir = input_dir  # path to images\n",
    "        self.csv_path = csv_path  # path to CSV\n",
    "        self.mini_batch_size = mini_batch_size  # number of images per mini batch\n",
    "        self.augmentation_fn = augmentation_fn  # augmentation function\n",
    "        \n",
    "        # Read CSV\n",
    "        self.df = pd.DataFrame.from_csv(csv_path)\n",
    "        \n",
    "        # Info\n",
    "        self.n_samples = len(self.df)\n",
    "        self.n_batches = self.n_samples // self.mini_batch_size\n",
    "        \n",
    "        # Macro batch related\n",
    "        self.macro_batch_size = macro_batch_size # size of bigger batch to take mini batches from\n",
    "        self.macro_batch_ids = [] # initialize empty macro batch\n",
    "        basic_df = pd.DataFrame.from_csv(join(data_dir, \"csv/train_labels.csv\"))\n",
    "        self.evaluated = basic_df['labelId'].apply(lambda x: ast.literal_eval(x)) # idx to int\n",
    "        idx_csv_df = pd.DataFrame.from_csv(join(data_dir, 'csv/idx_per_label.csv'))\n",
    "        self.idx_label_df = idx_csv_df['imageIdx'].apply(lambda x: ast.literal_eval(x)) # labels to int\n",
    "        \n",
    "        # Print some info\n",
    "        print('BatchGenerator detected: {n_samples} image samples.'.format(n_samples=self.n_samples))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Provide length in number of batches\n",
    "        return self.n_batches\n",
    "\n",
    "    def next(self):\n",
    "        \n",
    "        if len(self.macro_batch_ids) == 0:\n",
    "            self.create_macro_batch()\n",
    "        \n",
    "        # Take mini batch from macro batch\n",
    "        minibatch_ids = self.macro_batch_ids[:32]\n",
    "        self.macro_batch_ids = self.macro_batch_ids[32:]\n",
    "\n",
    "        # Take records with mini batch indices from dataframe\n",
    "        df_batch = self.df.iloc[minibatch_ids]\n",
    "\n",
    "        # Iterate over selected images \n",
    "        images = []\n",
    "        labels = []\n",
    "        for idx, row in df_batch.iterrows():\n",
    "\n",
    "            try:\n",
    "\n",
    "                # Read image path\n",
    "                img_id = row['imageId']\n",
    "                image_path = self.input_dir + \"/\" + str(img_id) + \".jpg\"\n",
    "\n",
    "                # Read data and label\n",
    "                image = load_image(image_path)\n",
    "                label = labels_one_hot(ast.literal_eval(row['labelId']))\n",
    "\n",
    "                # Data augmentation\n",
    "                if self.augmentation_fn:\n",
    "                    image = self.augmentation_fn(image)\n",
    "\n",
    "                # Append\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print('Failed reading image {idx}.jpg'.format(idx=img_id))\n",
    "            \n",
    "        # Assemble batch\n",
    "        batch_x = np.array(images)\n",
    "        batch_y = np.array(labels)\n",
    "\n",
    "        n_batches = self.macro_batch_size / self.mini_batch_size\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def create_macro_batch(self):\n",
    "        # Creates a macro_batch_size batch with each label at least once\n",
    "        image_ids = set([])\n",
    "        labels = set([])\n",
    "\n",
    "        # Go through labels in random order\n",
    "        label_range = list(range(1,229))\n",
    "        random.shuffle(label_range)\n",
    "        for label in [str(i) for i in label_range]:\n",
    "            if label not in labels:\n",
    "                # Add image with label to img_ids\n",
    "                img_id = random.choice(self.idx_label_df.iloc[int(label)-1]) + 1\n",
    "                image_ids = image_ids | set([img_id]) # add id\n",
    "\n",
    "                # Add labels from taken image to labels\n",
    "                new_labels = self.evaluated.iloc[img_id - 1]\n",
    "                labels = labels | set(new_labels)\n",
    "                all_labels.append(new_labels)\n",
    "\n",
    "        # Add images until size is right\n",
    "        while len(image_ids) < self.macro_batch_size:\n",
    "            image_ids = image_ids | set([random.randint(1, len(basic_df))])\n",
    "        \n",
    "        # Shuffle to be sure\n",
    "        image_ids = list(map(lambda x: x - 1, image_ids)) # from imageId to index\n",
    "        random.shuffle(image_ids)\n",
    "        \n",
    "        # Set macro batch and assert right length\n",
    "        self.macro_batch_ids = image_ids\n",
    "        assert(len(self.macro_batch_ids) == self.macro_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning:\n",
      "\n",
      "from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "\n",
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning:\n",
      "\n",
      "from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "\n",
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning:\n",
      "\n",
      "from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchGenerator detected: 1014544 image samples.\n"
     ]
    }
   ],
   "source": [
    "# Initialize generator (takes quite some time)\n",
    "training_gen = BalancedBatchGenerator(\n",
    "    input_dir = join(data_dir, \"train/\"),\n",
    "    csv_path = join(data_dir, \"csv/train_labels.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\neuralsnets\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning:\n",
      "\n",
      "`imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the generator\n",
    "all_batch_x = []\n",
    "all_batch_y = []\n",
    "count = 0\n",
    "for batch_x, batch_y in training_gen:\n",
    "#     print(batch_x.shape)\n",
    "#     print(batch_y.shape)\n",
    "#     plot_image(batch_x, images_per_row=8)\n",
    "    all_batch_x.append(batch_x)\n",
    "    all_batch_y.append(batch_y)\n",
    "    count = count + 1\n",
    "    if count == 16: # 512/32 = 16, exactly one macrobatch\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.  13.   3.   3.   2.   4.   7.   2.   8.   3.   6.   2.   4.  12.\n",
      "   3.   1. 131.  13.  72.  50.   1.   1.   1.   1.   3.   5.   1.   8.\n",
      "   3.   3.   3.   5.   3.   2.   1.  18.   3.   7.   2.   2.   1.   6.\n",
      "   3.  17.   3.   1.   7.   5.  25.   1.   8.   3.  75.   2.   6.   5.\n",
      "   1.   4.  17.   2.   5.  54.   9.   4.  10. 365.   2.   1.   7.  20.\n",
      "   4.   2.  19.   2.   1.   1.   4.  28.  31.   2.   3.   2.   1.   1.\n",
      "   2.   1.  19.   6.   2.   2.  20.   5.   2.   1.   9.   2.  15.  49.\n",
      "   9.   9.   4.   4.   6.   1. 155.  97.   1.   1.   3.  14.   3.   2.\n",
      "  50.   3.   8.  29.   5.   2.   2.   4.   4.  11.   2.   1.   2.   2.\n",
      "   3.  15.   2.   3.  34.   3.  30.   1.   4.   4.  53.  41.   4.   5.\n",
      "   3.  15.  10.  11.   1.   1.   4.  54.   1.   4.  19.   3. 121.  19.\n",
      "   8.   1.   1.  10.  10.   1.   1.   1.   1.  60.   6.   4.   7.   7.\n",
      "   2.  20. 110.   1.   1.   1.  18.  36.   2.   3.   2.  24.  16.   1.\n",
      "   8.  22.   1.  40.   4.   3.  13.  19.   1.   1.  12.   2.   2.   2.\n",
      "   2.   1.   3.   5.   2.   2.   7.   9.  16.   1.   1.   2.   1.   7.\n",
      "   1.   2.   2.  77.   1.   7.   4.  13.   1.   7.   1.  89.   1.   9.\n",
      "   2.  20.   4.   1.]\n"
     ]
    }
   ],
   "source": [
    "test = [np.sum(i, axis=0) for i in all_batch_y]\n",
    "test2 = np.sum(test, axis=0)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are no zeros in the array, which is a column-wise sum of all 16 batches, indicating that each label is selected at least once.\n",
    "## Ideas: parameters for training the best network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images seen: 20480000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "steps_per_epoch = 1600\n",
    "epochs = 400\n",
    "# 20 million = 20 times the whole data set\n",
    "print('Total images seen:', batch_size * steps_per_epoch * epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
